# -*- coding: utf-8 -*-
"""Model_Rekomendasi_Teja.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BkdKlpWhnZ3_nBnwjJiiKQ7ZeBPBR5Bw
"""

!pip install tensorflowjs

!pip install tensorflow==2.15.0

!pip3 install tensorflow_decision_forests==1.8.1

import tensorflowjs as tfjs
print(tfjs.__version__)

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import MinMaxScaler
import tensorflow as tf

data = pd.read_csv('/content/recommendation.csv')

data.info()

data['data_features'] = data['matched_tags'] + ", " + data['item_type'] + ", " + data['grade_nutriscore']
data = data[['id_user', 'kode', 'rating', "data_features"]]
data

data['data_features'] = data['data_features'].str.split(', ')

data_features = data['data_features'].apply(lambda x: pd.Series(1, index=x)).fillna(0).astype(int)
data_features

df_ratings_encode= pd.concat([data, data_features], axis=1)
df_ratings_encode

df_ratings_encode.drop(columns=['data_features'],inplace=True)
df_ratings_encode.info()

df_ratings_encode.head()

df_user = df_ratings_encode.copy()
df_user.drop(columns=['kode'],inplace=True)
df_user

for i in range(2, len(df_user.columns)):
    feature_column = df_user.columns[i]
    df_user[feature_column] = df_user.apply(lambda row: row['rating'] if row[feature_column] == 1 else np.nan,axis=1)

df_user

num_user_columns = df_user.columns[2:]
num_item_columns = df_user.columns[2:]

df_user_avg = df_user.groupby('id_user')[num_user_columns].mean().reset_index()
df_user_avg.fillna(0,inplace=True)
df_user_avg

df_user = pd.merge(df_user,df_user_avg,how='left',on='id_user')
num_columns_to_keep = 1 + len(num_user_columns)
num_columns_to_drop = len(df_user.columns) - num_columns_to_keep
df_user.drop(columns=df_user.columns[1:num_columns_to_drop + 1], inplace=True)
df_user.columns = ['id_user'] + num_user_columns.tolist()
df_user

df_item = df_ratings_encode.copy()
df_item.drop(columns=['kode'],inplace=True)
df_item.head()

rating = df_ratings_encode['rating'].values

scaler_user = StandardScaler()
scaler_item = StandardScaler()

scaler_user.fit(df_user[num_user_columns])
scaler_item.fit(df_item[num_item_columns])

df_user[num_user_columns] = scaler_user.transform(df_user[num_user_columns])
df_item[num_item_columns] = scaler_item.transform(df_item[num_item_columns])

df_user.head()

df_item.head()

scaler = MinMaxScaler((-1,1))
scaler.fit(rating.reshape(-1,1))
rating = scaler.transform(rating.reshape(-1,1))
rating

user_train, user_test, item_train, item_test, rating_train, rating_test = train_test_split(df_user[num_user_columns], df_item[num_item_columns], rating.flatten(), test_size=0.2, random_state=42)
user_test, user_val, item_test, item_val, rating_test, rating_val = train_test_split(user_test, item_test, rating_test, test_size=0.5, random_state=42)

user_train.shape, user_test.shape, user_val.shape, item_train.shape, item_test.shape, item_val.shape, rating_train.shape, rating_test.shape, rating_val.shape

num_features = len(num_user_columns)
num_features

num_features = len(num_user_columns)
embedding_dim = 32

# Definisi User Neural Network
user_NN = tf.keras.models.Sequential([
    tf.keras.layers.Dense(256, activation='relu'),
    tf.keras.layers.Dropout(0.3),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dropout(0.3),
    tf.keras.layers.Dense(embedding_dim, activation='linear'),
])

# Definisi Item Neural Network
item_NN = tf.keras.models.Sequential([
    tf.keras.layers.Dense(256, activation='relu'),
    tf.keras.layers.Dropout(0.3),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dropout(0.3),
    tf.keras.layers.Dense(embedding_dim, activation='linear'),
])

# Input dan Embedding untuk User
input_user = tf.keras.layers.Input(shape=(num_features,))
vu = user_NN(input_user)
vu = tf.keras.layers.Lambda(lambda x: tf.linalg.l2_normalize(x, axis=1))(vu)

# Input dan Embedding untuk Item
input_item = tf.keras.layers.Input(shape=(num_features,))
vm = item_NN(input_item)
vm = tf.keras.layers.Lambda(lambda x: tf.linalg.l2_normalize(x, axis=1))(vm)

# Perhitungan Similarity dengan Dot Product
output = tf.keras.layers.Dot(axes=1)([vu, vm])

# Definisi Model
model = tf.keras.Model(inputs=[input_user, input_item], outputs=output)

# Menampilkan Struktur Model
model.summary()

embedding_dim = 32

# Definisi User Neural Network
user_NN = tf.keras.Sequential([
    tf.keras.layers.Dense(256, activation='relu'),
    tf.keras.layers.Dropout(0.3),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dropout(0.3),
    tf.keras.layers.Dense(embedding_dim, activation='linear'),
])

# Definisi Item Neural Network
item_NN = tf.keras.Sequential([
    tf.keras.layers.Dense(256, activation='relu'),
    tf.keras.layers.Dropout(0.3),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dropout(0.3),
    tf.keras.layers.Dense(embedding_dim, activation='linear'),
])

# Input dan Embedding untuk User
input_user = tf.keras.Input(shape=(82,))
vu = user_NN(input_user)
vu = tf.keras.layers.LayerNormalization()(vu)

# Input dan Embedding untuk Item
input_item = tf.keras.Input(shape=(82,))
vm = item_NN(input_item)
vm = tf.keras.layers.LayerNormalization()(vm)

# Perhitungan Similarity dengan Dot Product
output = tf.keras.layers.Dot(axes=1)([vu, vm])

# Definisi Model
model = tf.keras.Model(inputs=[input_user, input_item], outputs=output)

# Menampilkan Struktur Model
model.summary()

cost_fn = tf.keras.losses.MeanSquaredError()
opt = tf.keras.optimizers.Adam(learning_rate=0.001)
model.compile(optimizer=opt,
              loss=cost_fn, metrics=['mse'])

history = model.fit([user_train, item_train], rating_train, epochs=25, verbose=2, batch_size=256, validation_data=([user_val, item_val], rating_val))

import random

# Daftar kolom
columns = ['id_user', 'rating', 'Minuman', 'Minuman pemanis buatan',
           'kemasan', 'B', 'Camilan asin', 'Kacang-kacangan', 'A',
           'Susu dan produk susu', 'Susu dan yogurt', 'Lemak dan saus', 'Lemak',
           'Camilan manis', 'Permen', 'E', 'Biskuit dan kue', 'D',
           'Sereal dan kentang', 'Sereal', 'Saus penambah rasa makanan',
           'Buah dan sayur', 'Buah-buahan', 'C', 'Roti', 'Sayur',
           'Makanan komposit', 'Makanan satu porsi', 'Ikan dan makanan laut',
           'Telur', 'Daging', 'Ikan', 'Minuman tanpa pemanis', 'Serealia olahan',
           'non-kemasan', 'Daging selain unggas', 'Kacang ', 'biji ', 'bean',
           'olahan', 'Produk asin dan berlemak', 'Minuman manis', 'Sandwich',
           'Sereal sarapan', 'Pengganti susu berbasis tanaman', 'Makanan pembuka',
           'Keju', 'unggas olahan', 'Ikan berlemak', 'Unggas', 'Daging olahan',
           'Es krim', 'kerang ', 'udang', 'Kue kering', 'Buah kering', 'Sayuran',
           'Telur olahan', 'Pizza dan quiche', 'Buah', 'Produk cokelat',
           'Lemak dan minyak', 'Sup', 'Pencuci mulut susu', 'Sayuran olahan',
           'Umbi berpati', 'Umbi berpati olahan', 'Bumbu', 'Serealia', 'Kentang',
           'Ikan berlemak sedikit', 'udang olahan', 'Gula ', 'sirup ',
           'konfeksioneri', 'Bumbu olahan', 'Susu olahan',
           'Teh dan teh herbal serta kopi', 'Susu', 'Buah olahan',
           'Lemak dan minyak olahan', 'Nektar buah', 'Sari buah', 'Jeroan']

# Kolom yang harus memiliki nilai
group_A_E = ['A', 'B', 'C', 'D', 'E']
group_packaging = ['kemasan', 'non-kemasan']

# Pilih salah satu dari setiap grup
selected_A_E = random.choice(group_A_E)
selected_packaging = random.choice(group_packaging)

# Pilih 1-5 kolom lainnya secara acak, hindari duplikasi dengan grup yang telah dipilih
available_columns = [col for col in columns if col not in group_A_E + group_packaging + ['id_user', 'rating']]
random_columns = random.sample(available_columns, k=random.randint(1, 5))

# Gabungkan semua kolom yang dipilih
final_columns = [selected_A_E, selected_packaging] + random_columns

# Buat data
new_user = {col: (1 if col in final_columns else 0) for col in columns if col not in ['id_user', 'rating']}
new_user['id_user'] = 500000
new_user['rating'] = np.random.randint(1, 6)

# Konversi ke DataFrame
new_user = pd.DataFrame([new_user])

for col in new_user.columns:
    if col not in ['id_user', 'rating']:
        new_user[col] = new_user[col] * new_user['rating']

new_user

import random
import pandas as pd
import numpy as np

# Daftar kolom
columns = ['id_user', 'rating', 'Minuman', 'Minuman pemanis buatan',
           'kemasan', 'B', 'Camilan asin', 'Kacang-kacangan', 'A',
           'Susu dan produk susu', 'Susu dan yogurt', 'Lemak dan saus', 'Lemak',
           'Camilan manis', 'Permen', 'E', 'Biskuit dan kue', 'D',
           'Sereal dan kentang', 'Sereal', 'Saus penambah rasa makanan',
           'Buah dan sayur', 'Buah-buahan', 'C', 'Roti', 'Sayur',
           'Makanan komposit', 'Makanan satu porsi', 'Ikan dan makanan laut',
           'Telur', 'Daging', 'Ikan', 'Minuman tanpa pemanis', 'Serealia olahan',
           'non-kemasan', 'Daging selain unggas', 'Kacang ', 'biji ', 'bean',
           'olahan', 'Produk asin dan berlemak', 'Minuman manis', 'Sandwich',
           'Sereal sarapan', 'Pengganti susu berbasis tanaman', 'Makanan pembuka',
           'Keju', 'unggas olahan', 'Ikan berlemak', 'Unggas', 'Daging olahan',
           'Es krim', 'kerang ', 'udang', 'Kue kering', 'Buah kering', 'Sayuran',
           'Telur olahan', 'Pizza dan quiche', 'Buah', 'Produk cokelat',
           'Lemak dan minyak', 'Sup', 'Pencuci mulut susu', 'Sayuran olahan',
           'Umbi berpati', 'Umbi berpati olahan', 'Bumbu', 'Serealia', 'Kentang',
           'Ikan berlemak sedikit', 'udang olahan', 'Gula ', 'sirup ',
           'konfeksioneri', 'Bumbu olahan', 'Susu olahan',
           'Teh dan teh herbal serta kopi', 'Susu', 'Buah olahan',
           'Lemak dan minyak olahan', 'Nektar buah', 'Sari buah', 'Jeroan']

# Kolom yang harus memiliki nilai selain id_user dan rating
allowed_tags = ['Sereal dan kentang', 'Sereal', 'kemasan', 'B']

# Simulasi data untuk id_user dan rating
new_user = {col: 0 for col in columns}
new_user['id_user'] = 500000  # Contoh id_user
new_user['rating'] = random.randint(1, 5)  # Contoh rating acak antara 1 dan 5

# Konversi ke DataFrame
new_user = pd.DataFrame([new_user])

# Pastikan semua kolom awal bernilai 0
for col in new_user.columns:
    if col not in ['id_user', 'rating'] + allowed_tags:
        new_user[col] = 0

# Berikan nilai hanya pada kolom yang termasuk dalam allowed_tags
for col in allowed_tags:
    if col in new_user.columns:
        new_user[col] = new_user['rating']

# Tampilkan hasil
new_user

# Menampilkan hanya kolom-kolom dengan nilai selain 0
non_zero_values = new_user.loc[:, (new_user != 0).any(axis=0)]
non_zero_values

new_user[num_user_columns] = scaler_user.transform(new_user[num_user_columns])

new_user = np.tile(new_user[num_user_columns], (df_item.shape[0], 1))
new_user.shape

predictions = model.predict([new_user, df_item[num_item_columns]])

predictions = scaler.inverse_transform(predictions)
sorted_predictions = np.argsort(predictions, axis=0)[::-1].flatten()
sorted_item = data.index.to_numpy()[sorted_predictions].flatten()
sorted_item

new_user_id = 500000

dic_predictions = {
    'userId': np.full((df_item.shape[0],), new_user_id),
    'index': data.iloc[sorted_item].index,
    'predictions': predictions[sorted_predictions].flatten()
}
df_predictions = pd.DataFrame(dic_predictions)
df_predictions.set_index('index', inplace=True)
df_predictions = pd.merge(df_predictions, data, how='left', left_index=True, right_index=True).reset_index(drop=True)
df_predictions.drop(columns=['id_user', 'rating'], inplace=True)
df_predictions.rename(columns={'id_user_x': 'id_user'}, inplace=True)
df_predictions.reset_index(drop=True,inplace=True)
df_predictions.head(30)

val_mse, val_loss = model.evaluate([user_val, item_val], rating_val, verbose=2)

plt.figure(figsize=(10, 8))
plt.plot(history.history['mse'], label='Training MSE')
plt.plot(history.history['val_mse'], label='Validation MSE')
plt.plot(val_mse, label='Validation mse', marker='o', markersize=10)
plt.legend()
plt.title('MSE Graph')
plt.show()

model.save('modell.h5')

tfjs.converters.save_keras_model(model, "contoh")

# Load the model from the H5 file
loaded_model = tf.keras.models.load_model('/content/model.h5')

try:
    loaded_model = tf.keras.models.load_model('/content/model.h5')
    print("Model loaded successfully. It contains architecture and weights.")
except Exception as e:
    print("Failed to load model:", e)

!tensorflowjs_converter --input_format=keras /content/modell.h5 /content/tfjss_model

import tensorflow as tf
print("TensorFlow version:", tf.__version__)

import keras
print("Keras version:", keras.__version__)

from google.colab import files
!zip -r hm_model.zip /content/tfjss_model
files.download('hm_model.zip')

